{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/04/07 18:12:39 INFO pig.ExecTypeProvider: Trying ExecType : LOCAL\n",
      "15/04/07 18:12:39 INFO pig.ExecTypeProvider: Picked LOCAL as the ExecType\n",
      "2015-04-07 18:12:39,932 [main] INFO  org.apache.pig.Main - Apache Pig version 0.14.0 (r1640057) compiled Nov 16 2014, 18:02:05\n",
      "2015-04-07 18:12:39,932 [main] INFO  org.apache.pig.Main - Logging error messages to: /home/python/pig_1428444759929.log\n",
      "2015-04-07 18:12:40,008 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "2015-04-07 18:12:41,069 [main] INFO  org.apache.pig.impl.util.Utils - Default bootup file /home/python/.pigbootup not found\n",
      "2015-04-07 18:12:41,285 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS\n",
      "2015-04-07 18:12:41,285 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2015-04-07 18:12:41,287 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - Connecting to hadoop file system at: file:///\n",
      "2015-04-07 18:12:41,664 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS\n",
      "2015-04-07 18:12:42,764 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS\n",
      "2015-04-07 18:12:43,366 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS\n",
      "2015-04-07 18:12:43,474 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: ORDER_BY,LIMIT\n",
      "2015-04-07 18:12:43,693 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS\n",
      "2015-04-07 18:12:43,876 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}\n",
      "2015-04-07 18:12:44,264 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler - File concatenation threshold: 100 optimistic? false\n",
      "2015-04-07 18:12:44,352 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR - Using Secondary Key Optimization for MapReduce node scope-17\n",
      "2015-04-07 18:12:44,365 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size before optimization: 4\n",
      "2015-04-07 18:12:44,377 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size after optimization: 4\n",
      "2015-04-07 18:12:44,449 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS\n",
      "2015-04-07 18:12:44,476 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "2015-04-07 18:12:44,477 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "2015-04-07 18:12:44,604 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2015-04-07 18:12:44,612 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2015-04-07 18:12:44,612 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2015-04-07 18:12:44,612 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2015-04-07 18:12:44,819 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2015-04-07 18:12:44,902 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Key [pig.schematuple] is false, will not generate code.\n",
      "2015-04-07 18:12:44,902 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Starting process to move generated code to distributed cacche\n",
      "2015-04-07 18:12:44,902 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Distributed cache not supported or needed in local mode. Setting key [pig.schematuple.local.dir] with code temp directory: /tmp/1428444764902-0\n",
      "2015-04-07 18:12:45,016 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2015-04-07 18:12:45,018 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address\n",
      "2015-04-07 18:12:45,089 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2015-04-07 18:12:45,189 [JobControl] WARN  org.apache.hadoop.mapreduce.JobSubmitter - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2015-04-07 18:12:45,385 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1\n",
      "2015-04-07 18:12:45,385 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2015-04-07 18:12:45,423 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2015-04-07 18:12:45,483 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2015-04-07 18:12:46,136 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local708251807_0001\n",
      "2015-04-07 18:12:47,067 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2015-04-07 18:12:47,082 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local708251807_0001\n",
      "2015-04-07 18:12:47,082 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases A,B\n",
      "2015-04-07 18:12:47,082 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: A[4,4],A[-1,-1],B[6,4] C:  R: \n",
      "2015-04-07 18:12:47,087 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 0% complete\n",
      "2015-04-07 18:12:47,088 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local708251807_0001]\n",
      "2015-04-07 18:12:47,107 [Thread-11] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2015-04-07 18:12:47,171 [Thread-11] INFO  org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS\n",
      "2015-04-07 18:12:47,172 [Thread-11] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2015-04-07 18:12:47,172 [Thread-11] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2015-04-07 18:12:47,201 [Thread-11] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2015-04-07 18:12:47,517 [Thread-11] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2015-04-07 18:12:47,524 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local708251807_0001_m_000000_0\n",
      "2015-04-07 18:12:47,854 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2015-04-07 18:12:47,884 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 1771685\n",
      "Input split[0]:\n",
      "   Length = 1771685\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2015-04-07 18:12:47,937 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/home/python/data/salarydata/BaltimoreSalaries.csv:0+1771685\n",
      "2015-04-07 18:12:48,088 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.data.SchemaTupleBackend - Key [pig.schematuple] was not set... will not generate code.\n",
      "2015-04-07 18:12:48,145 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapOnly$Map - Aliases being processed per job phase (AliasName[line,offset]): M: A[4,4],A[-1,-1],B[6,4] C:  R: \n",
      "2015-04-07 18:12:48,168 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.jar is deprecated. Instead, use mapreduce.job.jar\n",
      "2015-04-07 18:12:48,168 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
      "2015-04-07 18:12:48,168 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2015-04-07 18:12:53,734 [communication thread] INFO  org.apache.hadoop.mapred.LocalJobRunner - map > map\n",
      "2015-04-07 18:12:54,126 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 7% complete\n",
      "2015-04-07 18:12:54,127 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local708251807_0001]\n",
      "2015-04-07 18:12:55,150 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map > map\n",
      "2015-04-07 18:12:55,151 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local708251807_0001_m_000000_0 is done. And is in the process of committing\n",
      "2015-04-07 18:12:55,157 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map > map\n",
      "2015-04-07 18:12:55,157 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task attempt_local708251807_0001_m_000000_0 is allowed to commit now\n",
      "2015-04-07 18:12:55,194 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local708251807_0001_m_000000_0' to file:/tmp/temp679243619/tmp254327079/_temporary/0/task_local708251807_0001_m_000000\n",
      "2015-04-07 18:12:55,205 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2015-04-07 18:12:55,206 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local708251807_0001_m_000000_0' done.\n",
      "2015-04-07 18:12:55,206 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local708251807_0001_m_000000_0\n",
      "2015-04-07 18:12:55,207 [Thread-11] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2015-04-07 18:12:55,395 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 25% complete\n",
      "2015-04-07 18:12:55,398 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2015-04-07 18:12:55,412 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2015-04-07 18:12:55,413 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "2015-04-07 18:12:55,413 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2015-04-07 18:12:55,414 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2015-04-07 18:12:55,497 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2015-04-07 18:12:55,498 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2015-04-07 18:12:55,499 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2015-04-07 18:12:55,500 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n",
      "2015-04-07 18:12:55,502 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=1959934\n",
      "2015-04-07 18:12:55,504 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2015-04-07 18:12:55,521 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2015-04-07 18:12:55,629 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2015-04-07 18:12:55,630 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2015-04-07 18:12:55,635 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS\n",
      "2015-04-07 18:12:55,640 [JobControl] WARN  org.apache.hadoop.mapreduce.JobSubmitter - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2015-04-07 18:12:55,724 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1\n",
      "2015-04-07 18:12:55,724 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2015-04-07 18:12:55,724 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2015-04-07 18:12:55,727 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2015-04-07 18:12:55,790 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1097570364_0002\n",
      "2015-04-07 18:12:56,237 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2015-04-07 18:12:56,255 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local1097570364_0002\n",
      "2015-04-07 18:12:56,255 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases C\n",
      "2015-04-07 18:12:56,255 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: C[8,4] C:  R: \n",
      "2015-04-07 18:12:56,276 [Thread-21] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2015-04-07 18:12:56,326 [Thread-21] INFO  org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS\n",
      "2015-04-07 18:12:56,326 [Thread-21] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2015-04-07 18:12:56,326 [Thread-21] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2015-04-07 18:12:56,326 [Thread-21] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2015-04-07 18:12:56,327 [Thread-21] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2015-04-07 18:12:56,391 [Thread-21] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2015-04-07 18:12:56,392 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1097570364_0002_m_000000_0\n",
      "2015-04-07 18:12:56,430 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2015-04-07 18:12:56,488 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 1959934\n",
      "Input split[0]:\n",
      "   Length = 1959934\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2015-04-07 18:12:56,493 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp679243619/tmp254327079/part-m-00000:0+1959934\n",
      "2015-04-07 18:12:56,999 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2015-04-07 18:12:56,999 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2015-04-07 18:12:56,999 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2015-04-07 18:12:56,999 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2015-04-07 18:12:56,999 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2015-04-07 18:12:57,123 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2015-04-07 18:12:57,193 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2015-04-07 18:12:57,197 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: C[8,4] C:  R: \n",
      "2015-04-07 18:12:58,408 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2015-04-07 18:12:58,408 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2015-04-07 18:12:58,408 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2015-04-07 18:12:58,408 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1956; bufvoid = 104857600\n",
      "2015-04-07 18:12:58,408 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600\n",
      "2015-04-07 18:12:58,508 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2015-04-07 18:12:58,532 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1097570364_0002_m_000000_0 is done. And is in the process of committing\n",
      "2015-04-07 18:12:58,533 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2015-04-07 18:12:58,533 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1097570364_0002_m_000000_0' done.\n",
      "2015-04-07 18:12:58,534 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1097570364_0002_m_000000_0\n",
      "2015-04-07 18:12:58,534 [Thread-21] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2015-04-07 18:12:58,562 [Thread-21] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2015-04-07 18:12:58,563 [pool-5-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1097570364_0002_r_000000_0\n",
      "2015-04-07 18:12:58,611 [pool-5-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2015-04-07 18:12:58,677 [pool-5-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@71034e3b\n",
      "2015-04-07 18:12:58,752 [pool-5-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=709551680, maxSingleShuffleLimit=177387920, mergeThreshold=468304128, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2015-04-07 18:12:58,775 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 37% complete\n",
      "2015-04-07 18:12:58,776 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local1097570364_0002]\n",
      "2015-04-07 18:12:58,801 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1097570364_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2015-04-07 18:12:58,982 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1097570364_0002_m_000000_0 decomp: 2158 len: 2162 to MEMORY\n",
      "2015-04-07 18:12:59,027 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 2158 bytes from map-output for attempt_local1097570364_0002_m_000000_0\n",
      "2015-04-07 18:12:59,173 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 2158, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2158\n",
      "2015-04-07 18:12:59,218 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2015-04-07 18:12:59,219 [pool-5-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2015-04-07 18:12:59,219 [pool-5-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2015-04-07 18:12:59,256 [pool-5-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2015-04-07 18:12:59,256 [pool-5-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 2142 bytes\n",
      "2015-04-07 18:12:59,271 [pool-5-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 2158 bytes to disk to satisfy reduce memory limit\n",
      "2015-04-07 18:12:59,271 [pool-5-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 2162 bytes from disk\n",
      "2015-04-07 18:12:59,272 [pool-5-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2015-04-07 18:12:59,272 [pool-5-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2015-04-07 18:12:59,300 [pool-5-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 2142 bytes\n",
      "2015-04-07 18:12:59,300 [pool-5-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2015-04-07 18:12:59,324 [pool-5-thread-1] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2015-04-07 18:12:59,344 [pool-5-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2015-04-07 18:12:59,385 [pool-5-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: C[8,4] C:  R: \n",
      "2015-04-07 18:12:59,538 [pool-5-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1097570364_0002_r_000000_0 is done. And is in the process of committing\n",
      "2015-04-07 18:12:59,541 [pool-5-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2015-04-07 18:12:59,541 [pool-5-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1097570364_0002_r_000000_0 is allowed to commit now\n",
      "2015-04-07 18:12:59,543 [pool-5-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1097570364_0002_r_000000_0' to file:/tmp/temp679243619/tmp1392229819/_temporary/0/task_local1097570364_0002_r_000000\n",
      "2015-04-07 18:12:59,595 [pool-5-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2015-04-07 18:12:59,595 [pool-5-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1097570364_0002_r_000000_0' done.\n",
      "2015-04-07 18:12:59,595 [pool-5-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1097570364_0002_r_000000_0\n",
      "2015-04-07 18:12:59,595 [Thread-21] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2015-04-07 18:12:59,790 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 50% complete\n",
      "2015-04-07 18:12:59,792 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2015-04-07 18:12:59,793 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2015-04-07 18:12:59,794 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2015-04-07 18:12:59,822 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2015-04-07 18:12:59,823 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2015-04-07 18:12:59,824 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2015-04-07 18:12:59,824 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2015-04-07 18:12:59,892 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2015-04-07 18:13:00,041 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2015-04-07 18:13:00,102 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2015-04-07 18:13:00,155 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS\n",
      "2015-04-07 18:13:00,157 [JobControl] WARN  org.apache.hadoop.mapreduce.JobSubmitter - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2015-04-07 18:13:00,546 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1\n",
      "2015-04-07 18:13:00,546 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2015-04-07 18:13:00,546 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2015-04-07 18:13:00,551 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2015-04-07 18:13:00,643 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1974198384_0003\n",
      "2015-04-07 18:13:01,208 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2015-04-07 18:13:01,208 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local1974198384_0003\n",
      "2015-04-07 18:13:01,208 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases C\n",
      "2015-04-07 18:13:01,208 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: C[8,4] C:  R: \n",
      "2015-04-07 18:13:01,239 [Thread-30] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2015-04-07 18:13:01,248 [Thread-30] INFO  org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS\n",
      "2015-04-07 18:13:01,248 [Thread-30] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2015-04-07 18:13:01,248 [Thread-30] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2015-04-07 18:13:01,248 [Thread-30] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2015-04-07 18:13:01,249 [Thread-30] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2015-04-07 18:13:01,268 [Thread-30] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2015-04-07 18:13:01,268 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1974198384_0003_m_000000_0\n",
      "2015-04-07 18:13:01,305 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2015-04-07 18:13:01,308 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 1959934\n",
      "Input split[0]:\n",
      "   Length = 1959934\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2015-04-07 18:13:01,328 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp679243619/tmp254327079/part-m-00000:0+1959934\n",
      "2015-04-07 18:13:01,493 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2015-04-07 18:13:01,494 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2015-04-07 18:13:01,494 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2015-04-07 18:13:01,494 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2015-04-07 18:13:01,494 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2015-04-07 18:13:01,527 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2015-04-07 18:13:01,533 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2015-04-07 18:13:01,535 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: C[8,4] C:  R: \n",
      "2015-04-07 18:13:02,745 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2015-04-07 18:13:02,745 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2015-04-07 18:13:02,745 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2015-04-07 18:13:02,745 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1980476; bufvoid = 104857600\n",
      "2015-04-07 18:13:02,745 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26138476(104553904); length = 75921/6553600\n",
      "2015-04-07 18:13:03,067 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigCombiner$Combine - Aliases being processed per job phase (AliasName[line,offset]): M: C[8,4] C:  R: \n",
      "2015-04-07 18:13:04,426 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2015-04-07 18:13:04,469 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1974198384_0003_m_000000_0 is done. And is in the process of committing\n",
      "2015-04-07 18:13:04,485 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2015-04-07 18:13:04,485 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1974198384_0003_m_000000_0' done.\n",
      "2015-04-07 18:13:04,485 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1974198384_0003_m_000000_0\n",
      "2015-04-07 18:13:04,486 [Thread-30] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2015-04-07 18:13:04,513 [Thread-30] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2015-04-07 18:13:04,513 [pool-10-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1974198384_0003_r_000000_0\n",
      "2015-04-07 18:13:04,562 [pool-10-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2015-04-07 18:13:04,562 [pool-10-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@14ddc\n",
      "2015-04-07 18:13:04,630 [pool-10-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=709551680, maxSingleShuffleLimit=177387920, mergeThreshold=468304128, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2015-04-07 18:13:04,715 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1974198384_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2015-04-07 18:13:04,768 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1974198384_0003_m_000000_0 decomp: 1688 len: 1692 to MEMORY\n",
      "2015-04-07 18:13:04,782 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 62% complete\n",
      "2015-04-07 18:13:04,782 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local1974198384_0003]\n",
      "2015-04-07 18:13:04,786 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1688 bytes from map-output for attempt_local1974198384_0003_m_000000_0\n",
      "2015-04-07 18:13:04,786 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1688, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1688\n",
      "2015-04-07 18:13:04,787 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2015-04-07 18:13:04,793 [pool-10-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2015-04-07 18:13:04,793 [pool-10-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2015-04-07 18:13:04,796 [pool-10-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2015-04-07 18:13:04,797 [pool-10-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1680 bytes\n",
      "2015-04-07 18:13:04,804 [pool-10-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1688 bytes to disk to satisfy reduce memory limit\n",
      "2015-04-07 18:13:04,805 [pool-10-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1692 bytes from disk\n",
      "2015-04-07 18:13:04,805 [pool-10-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2015-04-07 18:13:04,805 [pool-10-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2015-04-07 18:13:04,830 [pool-10-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1680 bytes\n",
      "2015-04-07 18:13:04,831 [pool-10-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2015-04-07 18:13:04,842 [pool-10-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2015-04-07 18:13:04,867 [pool-10-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: C[8,4] C:  R: \n",
      "2015-04-07 18:13:05,283 [pool-10-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1974198384_0003_r_000000_0 is done. And is in the process of committing\n",
      "2015-04-07 18:13:05,285 [pool-10-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2015-04-07 18:13:05,285 [pool-10-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1974198384_0003_r_000000_0 is allowed to commit now\n",
      "2015-04-07 18:13:05,288 [pool-10-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1974198384_0003_r_000000_0' to file:/tmp/temp679243619/tmp789189534/_temporary/0/task_local1974198384_0003_r_000000\n",
      "2015-04-07 18:13:05,305 [pool-10-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2015-04-07 18:13:05,305 [pool-10-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1974198384_0003_r_000000_0' done.\n",
      "2015-04-07 18:13:05,305 [pool-10-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1974198384_0003_r_000000_0\n",
      "2015-04-07 18:13:05,306 [Thread-30] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2015-04-07 18:13:05,306 [Readahead Thread #2] WARN  org.apache.hadoop.io.ReadaheadPool - Failed readahead on ifile\n",
      "EBADF: Bad file descriptor\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n",
      "\tat java.lang.Thread.run(Thread.java:745)\n",
      "2015-04-07 18:13:05,854 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 75% complete\n",
      "2015-04-07 18:13:05,854 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local1974198384_0003]\n",
      "2015-04-07 18:13:05,959 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2015-04-07 18:13:06,012 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2015-04-07 18:13:06,013 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2015-04-07 18:13:06,019 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2015-04-07 18:13:06,019 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2015-04-07 18:13:06,020 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2015-04-07 18:13:06,020 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2015-04-07 18:13:06,031 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2015-04-07 18:13:06,091 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2015-04-07 18:13:06,191 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2015-04-07 18:13:06,212 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS\n",
      "2015-04-07 18:13:06,217 [JobControl] WARN  org.apache.hadoop.mapreduce.JobSubmitter - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2015-04-07 18:13:06,439 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1\n",
      "2015-04-07 18:13:06,439 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2015-04-07 18:13:06,439 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2015-04-07 18:13:06,646 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2015-04-07 18:13:06,671 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local635316109_0004\n",
      "2015-04-07 18:13:06,986 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2015-04-07 18:13:06,986 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local635316109_0004\n",
      "2015-04-07 18:13:06,986 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases C\n",
      "2015-04-07 18:13:06,986 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: C[8,4] C:  R: \n",
      "2015-04-07 18:13:07,000 [Thread-39] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2015-04-07 18:13:07,007 [Thread-39] INFO  org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS\n",
      "2015-04-07 18:13:07,007 [Thread-39] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2015-04-07 18:13:07,007 [Thread-39] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2015-04-07 18:13:07,008 [Thread-39] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2015-04-07 18:13:07,008 [Thread-39] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2015-04-07 18:13:07,030 [Thread-39] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2015-04-07 18:13:07,031 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local635316109_0004_m_000000_0\n",
      "2015-04-07 18:13:07,042 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2015-04-07 18:13:07,045 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 1656\n",
      "Input split[0]:\n",
      "   Length = 1656\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2015-04-07 18:13:07,048 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp679243619/tmp789189534/part-r-00000:0+1656\n",
      "2015-04-07 18:13:07,254 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2015-04-07 18:13:07,254 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2015-04-07 18:13:07,254 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2015-04-07 18:13:07,254 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2015-04-07 18:13:07,255 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2015-04-07 18:13:07,270 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2015-04-07 18:13:07,290 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2015-04-07 18:13:07,293 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: C[8,4] C:  R: \n",
      "2015-04-07 18:13:07,307 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2015-04-07 18:13:07,307 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2015-04-07 18:13:07,307 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2015-04-07 18:13:07,307 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1656; bufvoid = 104857600\n",
      "2015-04-07 18:13:07,308 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214340(104857360); length = 57/6553600\n",
      "2015-04-07 18:13:07,310 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2015-04-07 18:13:07,332 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local635316109_0004_m_000000_0 is done. And is in the process of committing\n",
      "2015-04-07 18:13:07,366 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2015-04-07 18:13:07,366 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local635316109_0004_m_000000_0' done.\n",
      "2015-04-07 18:13:07,366 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local635316109_0004_m_000000_0\n",
      "2015-04-07 18:13:07,368 [Thread-39] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2015-04-07 18:13:07,392 [Thread-39] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2015-04-07 18:13:07,393 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local635316109_0004_r_000000_0\n",
      "2015-04-07 18:13:07,425 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2015-04-07 18:13:07,449 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4c98bd99\n",
      "2015-04-07 18:13:07,475 [pool-13-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=709551680, maxSingleShuffleLimit=177387920, mergeThreshold=468304128, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2015-04-07 18:13:07,515 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 87% complete\n",
      "2015-04-07 18:13:07,515 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local635316109_0004]\n",
      "2015-04-07 18:13:07,517 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local635316109_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2015-04-07 18:13:07,518 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#3 about to shuffle output of map attempt_local635316109_0004_m_000000_0 decomp: 1688 len: 1692 to MEMORY\n",
      "2015-04-07 18:13:07,519 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1688 bytes from map-output for attempt_local635316109_0004_m_000000_0\n",
      "2015-04-07 18:13:07,519 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1688, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1688\n",
      "2015-04-07 18:13:07,519 [Readahead Thread #0] WARN  org.apache.hadoop.io.ReadaheadPool - Failed readahead on ifile\n",
      "EBADF: Bad file descriptor\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n",
      "\tat java.lang.Thread.run(Thread.java:745)\n",
      "2015-04-07 18:13:07,520 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2015-04-07 18:13:07,521 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2015-04-07 18:13:07,521 [pool-13-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2015-04-07 18:13:07,523 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2015-04-07 18:13:07,523 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1680 bytes\n",
      "2015-04-07 18:13:07,524 [pool-13-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1688 bytes to disk to satisfy reduce memory limit\n",
      "2015-04-07 18:13:07,524 [pool-13-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1692 bytes from disk\n",
      "2015-04-07 18:13:07,524 [pool-13-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2015-04-07 18:13:07,524 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2015-04-07 18:13:07,524 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1680 bytes\n",
      "2015-04-07 18:13:07,525 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2015-04-07 18:13:07,532 [pool-13-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2015-04-07 18:13:07,537 [pool-13-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: C[8,4] C:  R: \n",
      "2015-04-07 18:13:07,581 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local635316109_0004_r_000000_0 is done. And is in the process of committing\n",
      "2015-04-07 18:13:07,584 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2015-04-07 18:13:07,584 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local635316109_0004_r_000000_0 is allowed to commit now\n",
      "2015-04-07 18:13:07,587 [pool-13-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local635316109_0004_r_000000_0' to file:/tmp/temp679243619/tmp2027769919/_temporary/0/task_local635316109_0004_r_000000\n",
      "2015-04-07 18:13:07,588 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2015-04-07 18:13:07,588 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local635316109_0004_r_000000_0' done.\n",
      "2015-04-07 18:13:07,588 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local635316109_0004_r_000000_0\n",
      "2015-04-07 18:13:07,588 [Thread-39] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2015-04-07 18:13:07,787 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2015-04-07 18:13:07,787 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2015-04-07 18:13:07,788 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2015-04-07 18:13:07,837 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 100% complete\n",
      "2015-04-07 18:13:07,842 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats - Script Statistics: \n",
      "\n",
      "HadoopVersion\tPigVersion\tUserId\tStartedAt\tFinishedAt\tFeatures\n",
      "2.6.0\t0.14.0\tpython\t2015-04-07 18:12:44\t2015-04-07 18:13:07\tORDER_BY,LIMIT\n",
      "\n",
      "Success!\n",
      "\n",
      "Job Stats (time in seconds):\n",
      "JobId\tMaps\tReduces\tMaxMapTime\tMinMapTime\tAvgMapTime\tMedianMapTime\tMaxReduceTime\tMinReduceTime\tAvgReduceTime\tMedianReducetime\tAlias\tFeature\tOutputs\n",
      "job_local1097570364_0002\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tC\tSAMPLER\t\n",
      "job_local1974198384_0003\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tC\tORDER_BY,COMBINER\t\n",
      "job_local635316109_0004\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tC\t\tfile:/tmp/temp679243619/tmp2027769919,\n",
      "job_local708251807_0001\t1\t0\tn/a\tn/a\tn/a\tn/a\t0\t0\t0\t0\tA,B\tMAP_ONLY\t\n",
      "\n",
      "Input(s):\n",
      "Successfully read 18981 records from: \"/home/python/data/salarydata\"\n",
      "\n",
      "Output(s):\n",
      "Successfully stored 15 records in: \"file:/tmp/temp679243619/tmp2027769919\"\n",
      "\n",
      "Counters:\n",
      "Total records written : 15\n",
      "Total bytes written : 0\n",
      "Spillable Memory Manager spill count : 0\n",
      "Total bags proactively spilled: 0\n",
      "Total records proactively spilled: 0\n",
      "\n",
      "Job DAG:\n",
      "job_local708251807_0001\t->\tjob_local1097570364_0002,\n",
      "job_local1097570364_0002\t->\tjob_local1974198384_0003,\n",
      "job_local1974198384_0003\t->\tjob_local635316109_0004,\n",
      "job_local635316109_0004\n",
      "\n",
      "\n",
      "2015-04-07 18:13:07,844 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2015-04-07 18:13:07,845 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2015-04-07 18:13:07,846 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2015-04-07 18:13:07,856 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2015-04-07 18:13:07,857 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2015-04-07 18:13:07,857 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2015-04-07 18:13:07,880 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2015-04-07 18:13:07,881 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2015-04-07 18:13:07,881 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2015-04-07 18:13:07,911 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2015-04-07 18:13:07,911 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2015-04-07 18:13:07,912 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2015-04-07 18:13:07,938 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Success!\n",
      "2015-04-07 18:13:07,944 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS\n",
      "2015-04-07 18:13:07,945 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2015-04-07 18:13:08,087 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1\n",
      "2015-04-07 18:13:08,087 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "(238772,\"Bernstein,Gregg L\",STATE'S ATTORNEY,A29001,States Attorneys Office ,01/03/2011,$238772.00,$238772.04)\n",
      "(193653,\"Batts,Anthony W\",EXECUTIVE LEVEL III,A99390,Police Department ,09/25/2012,$193800.00,$193653.69)\n",
      "(188328,\"Black,Harry E\",EXECUTIVE LEVEL III,A23001,FIN-Admin & Budgets ,01/30/2012,$190000.00,$188328.50)\n",
      "(185741,\"Charles,Ronnie E\",EXECUTIVE LEVEL III,A83001,HR-Human Resources ,07/05/2012,$200000.00,$185741.81)\n",
      "(176141,\"Nalewajko Jr,Stephen C\",POLICE LIEUTENANT EID,A99264,Police Department ,08/21/1981,$95087.00,$176141.33)\n",
      "(173876,\"Marcus Sr,Albert M\",POLICE OFFICER (EID),A99322,Police Department ,02/03/1975,$73012.00,$173876.84)\n",
      "(166442,\"Stokes,Charline B\",Battalion Fire Chief EMS EMT-P,A64460,Fire Department ,01/18/1988,$107307.00,$166442.42)\n",
      "(165892,\"Harris Jr,William\",POLICE SERGEANT,A99309,Police Department ,10/24/2000,$80612.00,$165892.21)\n",
      "(165270,\"Makanjuola,Rafiu T\",POLICE OFFICER (EID),A99061,Police Department ,07/30/1997,$67535.00,$165270.01)\n",
      "(165108,\"Cheelsman III,Charles H\",Battalion Fire Chief EMS EMT-P,A64460,Fire Department ,12/08/1980,$107307.00,$165108.50)\n",
      "(164332,\"Nilson,George A\",CITY SOLICITOR,A30001,Law Department ,01/16/2007,$163200.00,$164332.32)\n",
      "(161364,\"Rhoden,James\",POLICE LIEUTENANT EID,A99263,Police Department ,07/23/1992,$91891.00,$161364.34)\n",
      "(161219,\"Rawlings-Blake,Stephanie C\",MAYOR,A01001,Mayors Office ,12/07/1995,$163365.00,$161219.24)\n",
      "(157980,\"Johnson,William M\",EXECUTIVE LEVEL III,A49101,TRANS-Highways ,05/22/2013,$158100.00,$157980.79)\n",
      "(157163,\"Walsh,Patrick J\",Battalion Fire Chief Suppress,A64006,Fire Department ,07/09/1979,$112684.00,$157163.81)\n",
      "2015-04-07 18:13:08,185 [main] INFO  org.apache.pig.Main - Pig script completed in 29 seconds and 568 milliseconds (29568 ms)\n"
     ]
    }
   ],
   "source": [
    "# Pig script that finds the max pay\n",
    "# Yes, there is a ton of output\n",
    "!pig -x local /home/python/pig_scripts/max.pig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
